{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function preprocess_image at 0x00000229C8E3E948>\n"
     ]
    }
   ],
   "source": [
    "def preprocess_image(img):\n",
    "    means = [0.485, 0.456, 0.406]\n",
    "    stds = [0.229, 0.224, 0.225]\n",
    "\n",
    "    preprocessed_img = img[:, :, ::-1]\n",
    "    \n",
    "    for i in range(3):\n",
    "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] - means[i]\n",
    "        preprocessed_img[:, :, i] = preprocessed_img[:, :, i] / stds[i]\n",
    "    preprocessed_img = \\\n",
    "        np.ascontiguousarray(np.transpose(preprocessed_img, (2, 0, 1)))\n",
    "    preprocessed_img = torch.from_numpy(preprocessed_img)\n",
    "    preprocessed_img.unsqueeze_(0)\n",
    "    input = preprocessed_img.requires_grad_(True) # 입력에 대해서 gradient가 흐르게 만든다\n",
    "    return input\n",
    "\n",
    "input = preprocess_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function preprocess_image at 0x00000229C8E3E948>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(224, 224)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.imread('both.png', 1)\n",
    "img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "input = preprocess_image(img)\n",
    "img[:,:,2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_cam_on_image(img, mask):\n",
    "    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "    heatmap = np.float32(heatmap) / 255\n",
    "    cam = heatmap + np.float32(img)\n",
    "    cam = cam / np.max(cam)\n",
    "    cv2.imwrite(\"cam.jpg\", np.uint8(255 * cam))\n",
    "    \n",
    "    plt.imshow(cam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 처음에 Feature를 뽑아야함 -> 알파를 만들기 위한 작업을 해야댐.\n",
    "# 마지막 conv layer에 대한 graident를 뽑기 위한 작업을 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (downsample): Sequential(\n",
      "    (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "    (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      ")\n",
      "1\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n",
      "2\n",
      "Bottleneck(\n",
      "  (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "  (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for name, module in model.layer4._modules.items():\n",
    "    print(name)\n",
    "    print(module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(): # feature를 뽑는 모듈\n",
    "    # 모델의 마지막 layer만 뽑고 싶다. 그중에서는 0, 1, 2 -> 2번째 layer\n",
    "    def __init__(self, model, target_layers): # model에 cnn 모델들이 들어간다. target_layer는 원하는 layer\n",
    "        self.model = model\n",
    "        self.target_layers = target_layers\n",
    "        self.gradients = []\n",
    "        \n",
    "    def save_gradient(self, grad):\n",
    "        self.gradients.append(grad) # hook이 실행될때마다 기울기가 저장된다. append\n",
    "        \n",
    "    # ModelOutputs 클래스의 call함수에서 이쪽에 있는 call함수를 부른다. 인자는 x를 넣음.\n",
    "    def __call__(self, x): # layer에 대한 hook이 아닌 변수 x에 대한 hook\n",
    "        outputs = []\n",
    "        self.gradients = []\n",
    "        for name, module in model.layer4._moodules.items(): # model(resnet의 마지막 layer)\n",
    "            x = module(x)\n",
    "            if name in self.target_layers:  # 마지막 layer의 마지막 conv\n",
    "                x.register_hook(self.save_gradient)\n",
    "                outputs += [x]\n",
    "        return outputs, x\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutputs():\n",
    "    def __init__(self, model, feature_module, target_layers): # 진짜 모델, 타켓 레이어(4번째), 타켓 중 몇번째 레이어(2번쨰)\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.feature_extractor = FeatureExtractor(self.feature_module, target_layers)\n",
    "        \n",
    "    def get_gradients(self): # 저장된 gradient를 가져오는 함수\n",
    "        return self.feature_extractor.gradients\n",
    "        \n",
    "    def __call__(self, x): \n",
    "        target_activations= []\n",
    "        for name, module in self.model._modules.items(): # model(resnet)의 modules.item()\n",
    "            if module == self.feature_module: # 마지막 layer일때 feature_extractor(x) \n",
    "                target_activations, x = self.feature_extractor(x) # return -> outputs 리스트, x\n",
    "            elif 'avgpool' in name.lower():\n",
    "                x = module(x)\n",
    "                x = x.view(x.size(0), -1)\n",
    "            else:\n",
    "                x = module(x)\n",
    "                \n",
    "        return target_activations, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = ModelOutputs(model, model.layer4, ['2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GradCam:\n",
    "    def __init__(self, model, feature_module, target_layer_names, use_cuda):\n",
    "        self.model = model\n",
    "        self.feature_module = feature_module\n",
    "        self.model.eval()\n",
    "        self.cuda = use_cuda\n",
    "        if self.cuda:\n",
    "            self.model = model.cuda()\n",
    "            \n",
    "        self.extractor= ModelOutputs(self.model, self.feature_module, target_layer_names)\n",
    "        \n",
    "    def __call__(self, input, index=None):\n",
    "        if self.cuda:\n",
    "            features, output = self.extractor(input.cuda())\n",
    "        else:\n",
    "            features, output = self.extractor(input) # return -> target_activations 리스트, x\n",
    "            \n",
    "        if index == None:\n",
    "            index = np.argmax(output.cpu().data.numpy())\n",
    "            \n",
    "        one_hot = np.zeros((1, output.size()[-1]), dtype=np.float32)\n",
    "        one_hot[0][index]= 1\n",
    "        one_hot= torch.from_numpy(one_hot).requires_grad_(True)\n",
    "        \n",
    "        if self.cuda:\n",
    "            one_hot = torch.sum(one_hot.cuda() * output)\n",
    "        else:\n",
    "            one_hot = torch.sum(one_hot * output)\n",
    "        \n",
    "        self.feature_module.zero_grad()\n",
    "        self.model.zero_grad()\n",
    "        one_hot.backward(retain_graph = True)\n",
    "        \n",
    "        grads_val = self.extractor.get_gradients()[-1].cpu().data.numpy()\n",
    "        \n",
    "        target= features[-1]\n",
    "        target= target.cpu().data.numpy()[0, :]\n",
    "        \n",
    "        weights = np.mean(grads_val, axis=(2,3))[0, :]\n",
    "        cam = np.zeros(target.shape[1:], dtype=np.float32)\n",
    "        \n",
    "        for i, w in enumerate(weights):\n",
    "            cam += w * target[i, :, :]\n",
    "       \n",
    "        cam = np.maximum(cam, 0)\n",
    "        cam = cv2.resize(cam, input.shape[2:])\n",
    "        cam = cam - np.min(cam)\n",
    "        cam = cam / np.max(cam)\n",
    "        return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-93-17c0a24660f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0ma\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True) # imageNet으로 pretrained된 resnet 모델을 불러와서 사용\n",
    "\n",
    "grad_cam = GradCam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막 layer만 쓰고 싶다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function preprocess_image at 0x00000229C8E3E948>\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread('both.png', 1)\n",
    "img = np.float32(cv2.resize(img, (224, 224))) / 255\n",
    "input = preprocess_image(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1번 클래스: FeatureExtractor\n",
    "뽑고 싶은 모델의 layer를 선택 -> layer안에서의 마지막 layer\n",
    "gradient를 뽑기 위한 hook fuction을 사용 -> backward 할 때 사용한다\n",
    "gradient 저장하는 함수를 만든다.\n",
    "마지막 layer의 feature와 graident를 ㅃ뽀는다\n",
    "\n",
    "2번 클래스: MOdelOoutputs\n",
    "return 결과값에 대한 피쳐맵과 결과값이 나온다\n",
    "\n",
    "3번 클래스: 알파와 피쳐맵 곱해줌"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
